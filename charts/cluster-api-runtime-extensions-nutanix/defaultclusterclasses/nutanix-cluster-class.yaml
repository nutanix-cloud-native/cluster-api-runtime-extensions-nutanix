apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  labels:
    cluster.x-k8s.io/provider: nutanix
  name: nutanix-quick-start-kcfg-0
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          kubeletExtraArgs:
            cloud-provider: external
            eviction-hard: nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<15%,memory.available<100Mi,imagefs.inodesFree<10%
            tls-cipher-suites: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
      postKubeadmCommands:
      - echo "after kubeadm call" > /var/log/postkubeadm.log
      preKubeadmCommands:
      - echo "before kubeadm call" > /var/log/prekubeadm.log
      - hostnamectl set-hostname "{{ ds.meta_data.hostname }}"
      verbosity: 10
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: ClusterClass
metadata:
  labels:
    cluster.x-k8s.io/provider: nutanix
  name: nutanix-quick-start
spec:
  controlPlane:
    machineHealthCheck:
      maxUnhealthy: 40%
      nodeStartupTimeout: 10m
      unhealthyConditions:
      - status: "False"
        timeout: 300s
        type: Ready
      - status: Unknown
        timeout: 300s
        type: Ready
      - status: "True"
        timeout: 300s
        type: MemoryPressure
      - status: "True"
        timeout: 300s
        type: DiskPressure
      - status: "True"
        timeout: 300s
        type: PIDPressure
      - status: "True"
        timeout: 300s
        type: NetworkUnavailable
    machineInfrastructure:
      ref:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: NutanixMachineTemplate
        name: nutanix-quick-start-cp-nmt
    ref:
      apiVersion: controlplane.cluster.x-k8s.io/v1beta1
      kind: KubeadmControlPlaneTemplate
      name: nutanix-quick-start-kcpt
  infrastructure:
    ref:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: NutanixClusterTemplate
      name: nutanix-quick-start-nct
  patches:
  - external:
      discoverVariablesExtension: nutanixclusterconfigvars.cluster-api-runtime-extensions-nutanix
      generateExtension: nutanixclusterconfigpatch.cluster-api-runtime-extensions-nutanix
    name: cluster-config
  - external:
      discoverVariablesExtension: nutanixworkerconfigvars.cluster-api-runtime-extensions-nutanix
      generateExtension: nutanixworkerconfigpatch.cluster-api-runtime-extensions-nutanix
    name: worker-config
  workers:
    machineDeployments:
    - class: nutanix-quick-start-worker
      machineHealthCheck:
        maxUnhealthy: 40%
        nodeStartupTimeout: 10m
        unhealthyConditions:
        - status: "False"
          timeout: 300s
          type: Ready
        - status: Unknown
          timeout: 300s
          type: Ready
        - status: "True"
          timeout: 300s
          type: MemoryPressure
        - status: "True"
          timeout: 300s
          type: DiskPressure
        - status: "True"
          timeout: 300s
          type: PIDPressure
        - status: "True"
          timeout: 300s
          type: NetworkUnavailable
      template:
        bootstrap:
          ref:
            apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
            kind: KubeadmConfigTemplate
            name: nutanix-quick-start-kcfg-0
        infrastructure:
          ref:
            apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
            kind: NutanixMachineTemplate
            name: nutanix-quick-start-md-nmt
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlaneTemplate
metadata:
  labels:
    cluster.x-k8s.io/provider: nutanix
  name: nutanix-quick-start-kcpt
spec:
  template:
    spec:
      kubeadmConfigSpec:
        clusterConfiguration:
          apiServer:
            certSANs:
            - localhost
            - 127.0.0.1
            - 0.0.0.0
            extraArgs:
              cloud-provider: external
              tls-cipher-suites: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
          controllerManager:
            extraArgs:
              cloud-provider: external
              tls-cipher-suites: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
          scheduler:
            extraArgs:
              tls-cipher-suites: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
        files:
        - content: |
            apiVersion: v1
            kind: Pod
            metadata:
              name: kube-vip
              namespace: kube-system
            spec:
              containers:
                - name: kube-vip
                  image: ghcr.io/kube-vip/kube-vip:v0.6.4
                  imagePullPolicy: IfNotPresent
                  args:
                    - manager
                  env:
                    - name: vip_arp
                      value: "true"
                    - name: address
                      value: "control_plane_endpoint_ip"
                    - name: port
                      value: "control_plane_endpoint_port"
                    - name: vip_cidr
                      value: "32"
                    - name: cp_enable
                      value: "true"
                    - name: cp_namespace
                      value: kube-system
                    - name: vip_ddns
                      value: "false"
                    - name: vip_leaderelection
                      value: "true"
                    - name: vip_leaseduration
                      value: "15"
                    - name: vip_renewdeadline
                      value: "10"
                    - name: vip_retryperiod
                      value: "2"
                    - name: svc_enable
                      value: "false"
                    - name: lb_enable
                      value: "false"
                    - name: enableServicesElection
                      value: "false"
                  securityContext:
                    capabilities:
                      add:
                        - NET_ADMIN
                        - SYS_TIME
                        - NET_RAW
                  volumeMounts:
                    - mountPath: /etc/kubernetes/admin.conf
                      name: kubeconfig
                  resources: {}
              hostNetwork: true
              hostAliases:
                - hostnames:
                    - kubernetes
                  ip: 127.0.0.1
              volumes:
                - name: kubeconfig
                  hostPath:
                    type: FileOrCreate
                    path: /etc/kubernetes/admin.conf
            status: {}
          owner: root:root
          path: /etc/kubernetes/manifests/kube-vip.yaml
        initConfiguration:
          nodeRegistration:
            kubeletExtraArgs:
              cloud-provider: external
              eviction-hard: nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<15%,memory.available<100Mi,imagefs.inodesFree<10%
              tls-cipher-suites: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
        joinConfiguration:
          nodeRegistration:
            kubeletExtraArgs:
              cloud-provider: external
              eviction-hard: nodefs.available<10%,nodefs.inodesFree<5%,imagefs.available<15%,memory.available<100Mi,imagefs.inodesFree<10%
              tls-cipher-suites: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256
        postKubeadmCommands:
        - echo export KUBECONFIG=/etc/kubernetes/admin.conf >> /root/.bashrc
        - |
          KUBERNETES_VERSION_NO_V=${KUBERNETES_VERSION#v}
          VERSION_TO_COMPARE=1.29.0
          if [ "$(printf '%s\n' "$KUBERNETES_VERSION_NO_V" "$VERSION_TO_COMPARE" | sort -V | head -n1)" != "$KUBERNETES_VERSION_NO_V" ]; then
            if [ -f /run/kubeadm/kubeadm.yaml ]; then
              sed -i 's#path: /etc/kubernetes/super-admin.conf#path: /etc/kubernetes/admin.conf#' /etc/kubernetes/manifests/kube-vip.yaml;
            fi
          fi
        - echo "after kubeadm call" > /var/log/postkubeadm.log
        preKubeadmCommands:
        - echo "before kubeadm call" > /var/log/prekubeadm.log
        - hostnamectl set-hostname "{{ ds.meta_data.hostname }}"
        - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
        - echo "127.0.0.1   localhost" >>/etc/hosts
        - echo "127.0.0.1   kubernetes" >>/etc/hosts
        - echo "127.0.0.1   {{ ds.meta_data.hostname }}" >> /etc/hosts
        - |
          KUBERNETES_VERSION_NO_V=${KUBERNETES_VERSION#v}
          VERSION_TO_COMPARE=1.29.0
          if [ "$(printf '%s\n' "$KUBERNETES_VERSION_NO_V" "$VERSION_TO_COMPARE" | sort -V | head -n1)" != "$KUBERNETES_VERSION_NO_V" ]; then
            if [ -f /run/kubeadm/kubeadm.yaml ]; then
              sed -i 's#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#' /etc/kubernetes/manifests/kube-vip.yaml;
            fi
          fi
        useExperimentalRetryJoin: true
        verbosity: 10
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixClusterTemplate
metadata:
  labels:
    cluster.x-k8s.io/provider: nutanix
  name: nutanix-quick-start-nct
spec:
  template:
    spec:
      controlPlaneEndpoint:
        host: PLACEHOLDER
        port: 6443
      failureDomains: []
      prismCentral:
        address: PLACEHOLDER
        credentialRef:
          kind: Secret
          name: PLACEHOLDER
          namespace: default
        port: 9440
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixMachineTemplate
metadata:
  labels:
    cluster.x-k8s.io/provider: nutanix
  name: nutanix-quick-start-cp-nmt
spec:
  template:
    spec:
      bootType: legacy
      cluster:
        name: ""
        type: name
      image:
        name: ""
        type: name
      memorySize: 4Gi
      providerID: nutanix://vm-uuid
      subnet:
      - name: ""
        type: name
      systemDiskSize: 40Gi
      vcpuSockets: 2
      vcpusPerSocket: 1
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: NutanixMachineTemplate
metadata:
  labels:
    cluster.x-k8s.io/provider: nutanix
  name: nutanix-quick-start-md-nmt
spec:
  template:
    spec:
      bootType: legacy
      cluster:
        name: ""
        type: name
      image:
        name: ""
        type: name
      memorySize: 4Gi
      providerID: nutanix://vm-uuid
      subnet:
      - name: ""
        type: name
      systemDiskSize: 40Gi
      vcpuSockets: 2
      vcpusPerSocket: 1
